{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:50:54.700119: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 13:50:55.604722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:50:55.604836: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-12 13:50:55.680565: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 13:50:56.971740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:50:56.971863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:50:56.971872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_data_generator\n",
    "from src.regularizer import EvidenceRegularizer, EvidenceRegularizerLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:51:14.409312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-12 13:51:14.410568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.410955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.411222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.411332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.411670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.411852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.411910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.411965: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:51:14.412102: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-12 13:51:14.413815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dtrain, dtest = load_data_generator(name='cifar10', batch_size=1024, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_10_no_regularization():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(32,32,3)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(32, 3, padding='same', activation='tanh'))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(32,3,padding='same', activation='tanh'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64,3,padding='same',activation='tanh'))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64,3,padding='same',activation='tanh'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128,3,padding='same',activation='tanh'))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128,3,padding='same',activation='tanh'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1024,activation='tanh'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def add_regularization(vanilla_model, regularizer = None, layers = None, **kwargs):   \n",
    "    model = keras.models.Sequential()\n",
    "    if layers is None:\n",
    "        layers = range(1, len(vanilla_model.layers)-1)\n",
    "    for i, l in enumerate(vanilla_model.layers):\n",
    "        model.add(l)\n",
    "        if i in layers:\n",
    "            if regularizer is None:\n",
    "                pass\n",
    "            elif regularizer == 'l1':\n",
    "                l.kernel_regularizer = keras.regularizers.l1(**kwargs)\n",
    "            elif regularizer == 'l2':\n",
    "                l.kernel_regularizer = keras.regularizers.l2(**kwargs)\n",
    "            elif regularizer == 'dropout':\n",
    "                model.add(keras.layers.Dropout(**kwargs))\n",
    "            elif regularizer == 'evidence':\n",
    "                l.activity_regularizer = EvidenceRegularizer(**kwargs)\n",
    "            elif regularizer == 'evidence_layer':\n",
    "                model.add(EvidenceRegularizerLayer(**kwargs))\n",
    "            else:\n",
    "                raise ValueError(\"Unknown regularizer: %s\" % regularizer)\n",
    "    return model\n",
    "\n",
    "def create_all_models(vanilla_model_fun):\n",
    "    model = vanilla_model_fun()\n",
    "    dropout = add_regularization(vanilla_model=vanilla_model_fun(), regularizer='dropout', layers=[1, 4, 8, 11, 13], rate=0.2)\n",
    "    evidence = add_regularization(vanilla_model=vanilla_model_fun(), regularizer='evidence', layers=[1, 4, 8, 11, 13], threshold=100, cutoff=0.0, strength=1.0)\n",
    "    both = add_regularization(vanilla_model=vanilla_model_fun(), regularizer='evidence', layers=[1, 4, 8, 11, 13], threshold=100, cutoff=0.0, strength=1.0)\n",
    "    both = add_regularization(vanilla_model=both, regularizer='dropout', layers=[1, 4, 8, 11, 13], rate=0.2)\n",
    "    \n",
    "    return {'None': model, 'Dropout': dropout, 'Evidence-based': evidence, 'Both': both}\n",
    "\n",
    "def compile_and_fit_model(model, dtrain, dtest, compile_kwargs: Optional[dict] = None, fit_kwargs: Optional[dict] = None):\n",
    "    _compile_kwargs = dict(optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    if compile_kwargs is not None:\n",
    "        _compile_kwargs.update(**compile_kwargs)\n",
    "    model.compile(**_compile_kwargs)\n",
    "\n",
    "    _fit_kwargs = dict(x=dtrain, validation_data=dtest, epochs=50)\n",
    "    if fit_kwargs is not None:\n",
    "        _fit_kwargs.update(**fit_kwargs)\n",
    "    \n",
    "    history = model.fit(**_fit_kwargs)\n",
    "\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cifar_10_no_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/evidence/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=1e-6, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 [==============================] - 238s 5s/step - loss: 1.9375 - accuracy: 0.3101 - val_loss: 1.6559 - val_accuracy: 0.4167\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 276s 6s/step - loss: 1.5342 - accuracy: 0.4555 - val_loss: 1.4457 - val_accuracy: 0.4846\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 285s 6s/step - loss: 1.3679 - accuracy: 0.5161 - val_loss: 1.3186 - val_accuracy: 0.5316\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 285s 6s/step - loss: 1.2657 - accuracy: 0.5527 - val_loss: 1.2346 - val_accuracy: 0.5633\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 285s 6s/step - loss: 1.1678 - accuracy: 0.5878 - val_loss: 1.1424 - val_accuracy: 0.5897\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 285s 6s/step - loss: 1.0817 - accuracy: 0.6214 - val_loss: 1.0668 - val_accuracy: 0.6255\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 284s 6s/step - loss: 1.0045 - accuracy: 0.6496 - val_loss: 1.0131 - val_accuracy: 0.6486\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 278s 6s/step - loss: 0.9408 - accuracy: 0.6718 - val_loss: 0.9463 - val_accuracy: 0.6694\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 196s 4s/step - loss: 0.8919 - accuracy: 0.6903 - val_loss: 0.9266 - val_accuracy: 0.6772\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 190s 4s/step - loss: 0.8400 - accuracy: 0.7077 - val_loss: 0.8881 - val_accuracy: 0.6917\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 188s 4s/step - loss: 0.8007 - accuracy: 0.7254 - val_loss: 0.8724 - val_accuracy: 0.6990\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 186s 4s/step - loss: 0.7759 - accuracy: 0.7324 - val_loss: 0.8478 - val_accuracy: 0.7072\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 191s 4s/step - loss: 0.7305 - accuracy: 0.7498 - val_loss: 0.8239 - val_accuracy: 0.7126\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 187s 4s/step - loss: 0.7028 - accuracy: 0.7596 - val_loss: 0.8211 - val_accuracy: 0.7153\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 187s 4s/step - loss: 0.6752 - accuracy: 0.7703 - val_loss: 0.8032 - val_accuracy: 0.7235\n",
      "Epoch 16/50\n",
      "49/49 [==============================] - 187s 4s/step - loss: 0.6473 - accuracy: 0.7805 - val_loss: 0.7778 - val_accuracy: 0.7324\n",
      "Epoch 17/50\n",
      "49/49 [==============================] - 187s 4s/step - loss: 0.6174 - accuracy: 0.7916 - val_loss: 0.7715 - val_accuracy: 0.7316\n",
      "Epoch 18/50\n",
      "49/49 [==============================] - 181s 4s/step - loss: 0.5913 - accuracy: 0.8012 - val_loss: 0.7593 - val_accuracy: 0.7389\n",
      "Epoch 19/50\n",
      "49/49 [==============================] - 182s 4s/step - loss: 0.5672 - accuracy: 0.8102 - val_loss: 0.7577 - val_accuracy: 0.7381\n",
      "Epoch 20/50\n",
      "49/49 [==============================] - 215s 4s/step - loss: 0.5442 - accuracy: 0.8194 - val_loss: 0.7500 - val_accuracy: 0.7406\n",
      "Epoch 21/50\n",
      "49/49 [==============================] - 211s 4s/step - loss: 0.5155 - accuracy: 0.8291 - val_loss: 0.7338 - val_accuracy: 0.7466\n",
      "Epoch 22/50\n",
      "49/49 [==============================] - 202s 4s/step - loss: 0.4936 - accuracy: 0.8364 - val_loss: 0.7527 - val_accuracy: 0.7409\n",
      "Epoch 23/50\n",
      "49/49 [==============================] - 206s 4s/step - loss: 0.4763 - accuracy: 0.8430 - val_loss: 0.7324 - val_accuracy: 0.7470\n",
      "Epoch 24/50\n",
      "49/49 [==============================] - 209s 4s/step - loss: 0.4493 - accuracy: 0.8535 - val_loss: 0.7386 - val_accuracy: 0.7451\n",
      "Epoch 25/50\n",
      "49/49 [==============================] - 207s 4s/step - loss: 0.4291 - accuracy: 0.8607 - val_loss: 0.7344 - val_accuracy: 0.7511\n",
      "Epoch 26/50\n",
      "49/49 [==============================] - 204s 4s/step - loss: 0.4095 - accuracy: 0.8683 - val_loss: 0.7286 - val_accuracy: 0.7513\n",
      "Epoch 27/50\n",
      "49/49 [==============================] - 208s 4s/step - loss: 0.3886 - accuracy: 0.8754 - val_loss: 0.7251 - val_accuracy: 0.7543\n",
      "Epoch 28/50\n",
      "49/49 [==============================] - 207s 4s/step - loss: 0.3757 - accuracy: 0.8808 - val_loss: 0.7398 - val_accuracy: 0.7509\n",
      "Epoch 29/50\n",
      "49/49 [==============================] - 206s 4s/step - loss: 0.3471 - accuracy: 0.8921 - val_loss: 0.7301 - val_accuracy: 0.7523\n",
      "Epoch 30/50\n",
      "49/49 [==============================] - 205s 4s/step - loss: 0.3265 - accuracy: 0.8998 - val_loss: 0.7419 - val_accuracy: 0.7506\n",
      "Epoch 31/50\n",
      "49/49 [==============================] - 205s 4s/step - loss: 0.3042 - accuracy: 0.9100 - val_loss: 0.7328 - val_accuracy: 0.7565\n",
      "Epoch 32/50\n",
      "49/49 [==============================] - 206s 4s/step - loss: 0.2861 - accuracy: 0.9165 - val_loss: 0.7441 - val_accuracy: 0.7570\n",
      "Epoch 33/50\n",
      "49/49 [==============================] - 213s 4s/step - loss: 0.2671 - accuracy: 0.9249 - val_loss: 0.7412 - val_accuracy: 0.7550\n",
      "Epoch 34/50\n",
      "49/49 [==============================] - 209s 4s/step - loss: 0.2551 - accuracy: 0.9270 - val_loss: 0.7496 - val_accuracy: 0.7544\n",
      "Epoch 35/50\n",
      "49/49 [==============================] - 208s 4s/step - loss: 0.2346 - accuracy: 0.9372 - val_loss: 0.7577 - val_accuracy: 0.7533\n",
      "Epoch 36/50\n",
      "49/49 [==============================] - 198s 4s/step - loss: 0.2177 - accuracy: 0.9429 - val_loss: 0.7637 - val_accuracy: 0.7567\n",
      "Epoch 37/50\n",
      "49/49 [==============================] - 196s 4s/step - loss: 0.2025 - accuracy: 0.9486 - val_loss: 0.7734 - val_accuracy: 0.7528\n",
      "Epoch 38/50\n",
      "49/49 [==============================] - 208s 4s/step - loss: 0.1840 - accuracy: 0.9580 - val_loss: 0.7704 - val_accuracy: 0.7571\n",
      "Epoch 39/50\n",
      "49/49 [==============================] - 207s 4s/step - loss: 0.1707 - accuracy: 0.9627 - val_loss: 0.7777 - val_accuracy: 0.7571\n",
      "Epoch 40/50\n",
      "49/49 [==============================] - 207s 4s/step - loss: 0.1610 - accuracy: 0.9643 - val_loss: 0.7853 - val_accuracy: 0.7557\n",
      "Epoch 41/50\n",
      "49/49 [==============================] - 209s 4s/step - loss: 0.1428 - accuracy: 0.9733 - val_loss: 0.7901 - val_accuracy: 0.7572\n",
      "Epoch 42/50\n",
      "49/49 [==============================] - 207s 4s/step - loss: 0.1323 - accuracy: 0.9766 - val_loss: 0.8017 - val_accuracy: 0.7587\n",
      "Epoch 43/50\n",
      "49/49 [==============================] - 208s 4s/step - loss: 0.1207 - accuracy: 0.9814 - val_loss: 0.8034 - val_accuracy: 0.7572\n",
      "Epoch 44/50\n",
      "49/49 [==============================] - 207s 4s/step - loss: 0.1087 - accuracy: 0.9856 - val_loss: 0.8202 - val_accuracy: 0.7584\n",
      "Epoch 45/50\n",
      "49/49 [==============================] - 194s 4s/step - loss: 0.0980 - accuracy: 0.9888 - val_loss: 0.8265 - val_accuracy: 0.7573\n",
      "Epoch 46/50\n",
      "49/49 [==============================] - 197s 4s/step - loss: 0.0897 - accuracy: 0.9906 - val_loss: 0.8279 - val_accuracy: 0.7590\n",
      "Epoch 47/50\n",
      "49/49 [==============================] - 209s 4s/step - loss: 0.0803 - accuracy: 0.9934 - val_loss: 0.8442 - val_accuracy: 0.7578\n",
      "Epoch 48/50\n",
      "49/49 [==============================] - 202s 4s/step - loss: 0.0745 - accuracy: 0.9949 - val_loss: 0.8477 - val_accuracy: 0.7584\n",
      "Epoch 49/50\n",
      "49/49 [==============================] - 214s 4s/step - loss: 0.0677 - accuracy: 0.9958 - val_loss: 0.8660 - val_accuracy: 0.7556\n",
      "Epoch 50/50\n",
      "49/49 [==============================] - 199s 4s/step - loss: 0.0631 - accuracy: 0.9968 - val_loss: 0.8732 - val_accuracy: 0.7579\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=dtrain, validation_data=dtest, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_all_models(cifar_10_no_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 [==============================] - 213s 4s/step - loss: 1.9568 - accuracy: 0.3005 - val_loss: 1.6522 - val_accuracy: 0.4186\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 211s 4s/step - loss: 1.5530 - accuracy: 0.4482 - val_loss: 1.4503 - val_accuracy: 0.4856\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 210s 4s/step - loss: 1.3906 - accuracy: 0.5066 - val_loss: 1.3414 - val_accuracy: 0.5186\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 209s 4s/step - loss: 1.2732 - accuracy: 0.5478 - val_loss: 1.2331 - val_accuracy: 0.5582\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 218s 4s/step - loss: 1.1703 - accuracy: 0.5874 - val_loss: 1.1475 - val_accuracy: 0.5895\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 215s 4s/step - loss: 1.0986 - accuracy: 0.6145 - val_loss: 1.0912 - val_accuracy: 0.6133\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 215s 4s/step - loss: 1.0134 - accuracy: 0.6464 - val_loss: 1.0249 - val_accuracy: 0.6397\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 212s 4s/step - loss: 0.9515 - accuracy: 0.6674 - val_loss: 0.9837 - val_accuracy: 0.6554\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 213s 4s/step - loss: 0.9144 - accuracy: 0.6811 - val_loss: 0.9481 - val_accuracy: 0.6660\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 213s 4s/step - loss: 0.8532 - accuracy: 0.7040 - val_loss: 0.8975 - val_accuracy: 0.6839\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 212s 4s/step - loss: 0.8123 - accuracy: 0.7188 - val_loss: 0.8837 - val_accuracy: 0.6901\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 209s 4s/step - loss: 0.7794 - accuracy: 0.7307 - val_loss: 0.8634 - val_accuracy: 0.7006\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 204s 4s/step - loss: 0.7472 - accuracy: 0.7429 - val_loss: 0.8486 - val_accuracy: 0.7012\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 203s 4s/step - loss: 0.7121 - accuracy: 0.7563 - val_loss: 0.8272 - val_accuracy: 0.7138\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 204s 4s/step - loss: 0.6864 - accuracy: 0.7645 - val_loss: 0.8121 - val_accuracy: 0.7159\n",
      "Epoch 16/50\n",
      "17/49 [=========>....................] - ETA: 2:14 - loss: 0.6573 - accuracy: 0.7764"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m histories \u001b[38;5;241m=\u001b[39m {key: compile_and_fit_model(model\u001b[38;5;241m=\u001b[39mm, dtrain\u001b[38;5;241m=\u001b[39mdtrain, dtest\u001b[38;5;241m=\u001b[39mdtest) \u001b[38;5;28;01mfor\u001b[39;00m key, m \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m histories \u001b[38;5;241m=\u001b[39m {key: \u001b[43mcompile_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtest\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, m \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "Cell \u001b[0;32mIn [6], line 69\u001b[0m, in \u001b[0;36mcompile_and_fit_model\u001b[0;34m(model, dtrain, dtest, compile_kwargs, fit_kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     _fit_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m---> 69\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/evidence/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = {key: compile_and_fit_model(model=m, dtrain=dtrain, dtest=dtest) for key, m in models.items() if key != 'None'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories['None'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('evidence')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b730dbfddf4b5115c906e99f896976cc40df251fdaaf64f8c5caedf6a9ad9855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
